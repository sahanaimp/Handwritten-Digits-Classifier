{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the PATH to include the user installation directory. \n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.environ['PATH']}:/root/.local/bin\"\n",
    "\n",
    "# Restart the Kernel before you move on to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this project, you will build a neural network of your own design to evaluate the MNIST dataset.\n",
    "\n",
    "Some of the benchmark results on MNIST include can be found [on Yann LeCun's page](https://webcache.googleusercontent.com/search?q=cache:stAVPik6onEJ:yann.lecun.com/exdb/mnist) and include:\n",
    "\n",
    "88% [Lecun et al., 1998](https://hal.science/hal-03926082/document)\n",
    "\n",
    "95.3% [Lecun et al., 1998](https://hal.science/hal-03926082v1/document)\n",
    "\n",
    "99.65% [Ciresan et al., 2011](http://people.idsia.ch/~juergen/ijcai2011.pdf)\n",
    "\n",
    "\n",
    "MNIST is a great dataset for sanity checking your models, since the accuracy levels achieved by large convolutional neural networks and small linear models are both quite high. This makes it important to be familiar with the data.\n",
    "\n",
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important: Restart the Kernel before you move on to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python-headless==4.5.3.56\n",
      "  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 37.1 MB 857 kB/s eta 0:00:01    |████████▋                       | 9.9 MB 857 kB/s eta 0:00:32\n",
      "\u001b[?25hRequirement already satisfied: matplotlib==3.4.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (3.4.3)\n",
      "Requirement already satisfied: numpy==1.21.2 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (1.21.2)\n",
      "Requirement already satisfied: pillow==7.0.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (7.0.0)\n",
      "Collecting bokeh==2.1.1\n",
      "  Downloading bokeh-2.1.1.tar.gz (19.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.3 MB 64.1 MB/s eta 0:00:01\n",
      "Collecting torchvision==0.12.0\n",
      "  Downloading torchvision-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.0 MB 55.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm==4.63.0\n",
      "  Downloading tqdm-4.63.0-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 7.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting ipywidgets==7.7.0\n",
      "  Downloading ipywidgets-7.7.0-py2.py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 71.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting livelossplot==0.5.4\n",
      "  Downloading livelossplot-0.5.4-py3-none-any.whl (22 kB)\n",
      "Collecting pytest==7.1.1\n",
      "  Downloading pytest-7.1.1-py3-none-any.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 64.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas==1.3.5\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 42.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting seaborn==0.11.2\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[K     |████████████████████████████████| 292 kB 59.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter==1.0.0\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Collecting ipykernel==4.10.0\n",
      "  Downloading ipykernel-4.10.0-py3-none-any.whl (109 kB)\n",
      "\u001b[K     |████████████████████████████████| 109 kB 77.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 2)) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 2)) (0.10.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.1.1->-r requirements.txt (line 5)) (5.3)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.1.1->-r requirements.txt (line 5)) (2.11.1)\n",
      "Requirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.1.1->-r requirements.txt (line 5)) (20.1)\n",
      "Requirement already satisfied: tornado>=5.1 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.1.1->-r requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.1.1->-r requirements.txt (line 5)) (3.7.4.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0->-r requirements.txt (line 7)) (2.23.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.7.0->-r requirements.txt (line 9)) (4.3.3)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.7.0->-r requirements.txt (line 9)) (7.13.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.2.0)\n",
      "Collecting widgetsnbextension~=3.6.0\n",
      "  Downloading widgetsnbextension-3.6.6-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 69.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyterlab-widgets>=1.0.0; python_version >= \"3.6\"\n",
      "  Downloading jupyterlab_widgets-3.0.11-py3-none-any.whl (214 kB)\n",
      "\u001b[K     |████████████████████████████████| 214 kB 55.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets==7.7.0->-r requirements.txt (line 9)) (5.0.4)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from pytest==7.1.1->-r requirements.txt (line 11)) (19.3.0)\n",
      "Collecting pluggy<2.0,>=0.12\n",
      "  Downloading pluggy-1.2.0-py3-none-any.whl (17 kB)\n",
      "Collecting py>=1.8.2\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 11.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting iniconfig\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Collecting tomli>=1.0.0\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from pytest==7.1.1->-r requirements.txt (line 11)) (1.5.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas==1.3.5->-r requirements.txt (line 12)) (2019.3)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.7/site-packages (from seaborn==0.11.2->-r requirements.txt (line 13)) (1.7.1)\n",
      "Collecting jupyter-console\n",
      "  Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from jupyter==1.0.0->-r requirements.txt (line 14)) (5.6.1)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.7/site-packages (from jupyter==1.0.0->-r requirements.txt (line 14)) (5.7.4)\n",
      "Collecting qtconsole\n",
      "  Downloading qtconsole-5.4.4-py3-none-any.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 67.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jupyter-client in /opt/conda/lib/python3.7/site-packages (from ipykernel==4.10.0->-r requirements.txt (line 15)) (6.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib==3.4.3->-r requirements.txt (line 2)) (45.2.0.post20200209)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib==3.4.3->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=2.7->bokeh==2.1.1->-r requirements.txt (line 5)) (1.1.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 7)) (1.25.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 7)) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 7)) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 7)) (2019.11.28)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets==7.7.0->-r requirements.txt (line 9)) (4.4.2)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.1.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.16.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (2.5.2)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (3.0.3)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets==7.7.0->-r requirements.txt (line 9)) (3.2.0)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets==7.7.0->-r requirements.txt (line 9)) (4.6.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest==7.1.1->-r requirements.txt (line 11)) (3.0.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.7/site-packages (from jupyter-console->jupyter==1.0.0->-r requirements.txt (line 14)) (19.0.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (0.3)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (3.1.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (1.4.2)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (0.6.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (0.8.4)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (0.4.4)\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 14)) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 14)) (0.8.3)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 14)) (0.7.1)\n",
      "Collecting qtpy>=2.4.0\n",
      "  Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[K     |████████████████████████████████| 93 kB 3.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: parso>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.6.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.1.8)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets==7.7.0->-r requirements.txt (line 9)) (0.15.7)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 14)) (0.5.1)\n",
      "Building wheels for collected packages: bokeh\n",
      "  Building wheel for bokeh (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bokeh: filename=bokeh-2.1.1-py3-none-any.whl size=9257186 sha256=465fe402e8d0e31859956ec7d91365dc31cfa12010c9cc306164fedf46c70716\n",
      "  Stored in directory: /root/.cache/pip/wheels/f7/55/ff/f3d7554e69382d31cf7ad857cf518af9b923134fca7d925187\n",
      "Successfully built bokeh\n",
      "\u001b[31mERROR: jupyter-console 6.6.3 has requirement ipykernel>=6.14, but you'll have ipykernel 4.10.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyter-console 6.6.3 has requirement jupyter-client>=7.0.0, but you'll have jupyter-client 6.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyter-console 6.6.3 has requirement jupyter-core!=5.0.*,>=4.12, but you'll have jupyter-core 4.6.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyter-console 6.6.3 has requirement prompt-toolkit>=3.0.30, but you'll have prompt-toolkit 3.0.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyter-console 6.6.3 has requirement traitlets>=5.4, but you'll have traitlets 4.3.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: opencv-python-headless, bokeh, torchvision, tqdm, ipykernel, widgetsnbextension, jupyterlab-widgets, ipywidgets, livelossplot, pluggy, py, iniconfig, tomli, pytest, pandas, seaborn, jupyter-console, qtpy, qtconsole, jupyter\n",
      "Successfully installed bokeh-2.1.1 iniconfig-2.0.0 ipykernel-4.10.0 ipywidgets-7.7.0 jupyter-1.0.0 jupyter-console-6.6.3 jupyterlab-widgets-3.0.11 livelossplot-0.5.4 opencv-python-headless-4.5.3.56 pandas-1.3.5 pluggy-1.2.0 py-1.11.0 pytest-7.1.1 qtconsole-5.4.4 qtpy-2.4.1 seaborn-0.11.2 tomli-2.0.1 torchvision-0.12.0 tqdm-4.63.0 widgetsnbextension-3.6.6\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n",
      "\u001b[K     |████████████████████████████████| 139 kB 896 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting widgetsnbextension~=4.0.11\n",
      "  Downloading widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 7.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: jupyterlab-widgets~=3.0.11 in /root/.local/lib/python3.7/site-packages (from ipywidgets) (3.0.11)\n",
      "Collecting comm>=0.1.3\n",
      "  Downloading comm-0.1.4-py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied, skipping upgrade: ipython>=6.1.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (7.13.0)\n",
      "Requirement already satisfied, skipping upgrade: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (4.3.3)\n",
      "Requirement already satisfied, skipping upgrade: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (2.5.2)\n",
      "Requirement already satisfied, skipping upgrade: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (45.2.0.post20200209)\n",
      "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.3)\n",
      "Requirement already satisfied, skipping upgrade: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied, skipping upgrade: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied, skipping upgrade: parso>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython>=6.1.0->ipywidgets) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=6.1.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.1.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: widgetsnbextension, comm, ipywidgets\n",
      "  Attempting uninstall: widgetsnbextension\n",
      "    Found existing installation: widgetsnbextension 3.6.6\n",
      "    Uninstalling widgetsnbextension-3.6.6:\n",
      "      Successfully uninstalled widgetsnbextension-3.6.6\n",
      "  Attempting uninstall: ipywidgets\n",
      "    Found existing installation: ipywidgets 7.7.0\n",
      "    Uninstalling ipywidgets-7.7.0:\n",
      "      Successfully uninstalled ipywidgets-7.7.0\n",
      "Successfully installed comm-0.1.4 ipywidgets-8.1.3 widgetsnbextension-4.0.11\n"
     ]
    }
   ],
   "source": [
    "# Install requirements\n",
    "!python -m pip install -r requirements.txt\n",
    "!pip install ipywidgets --upgrade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell contains the essential imports you will need – DO NOT CHANGE THE CONTENTS! ##\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "Specify your transforms as a list if you intend to .\n",
    "The transforms module is already loaded as `transforms`.\n",
    "\n",
    "MNIST is fortunately included in the torchvision module.\n",
    "Then, you can create your dataset using the `MNIST` object from `torchvision.datasets` ([the documentation is available here](https://pytorch.org/vision/stable/datasets.html#mnist)).\n",
    "Make sure to specify `download=True`! \n",
    "\n",
    "Once your dataset is created, you'll also need to define a `DataLoader` from the `torch.utils.data` module for both the train and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 60000\n",
      "Number of batches in training dataloader: 938\n",
      "Test dataset size: 10000\n",
      "Number of batches in test dataloader: 10\n",
      "Batch of images shape: torch.Size([64, 1, 28, 28])\n",
      "Batch of labels shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Define transforms\n",
    "## YOUR CODE HERE ##\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define transformations for the training and test sets\n",
    "transform_list = [\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize with MNIST mean and std\n",
    "]\n",
    "\n",
    "transform = transforms.Compose(transform_list)\n",
    "\n",
    "\n",
    "\n",
    "# Create training set and define training dataloader\n",
    "## YOUR CODE HERE ##\n",
    "\n",
    "# Create the training dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# Define the training DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "# Create test set and define test dataloader\n",
    "## YOUR CODE HERE ##\n",
    "# Create the test dataset\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Define the test DataLoader\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1000, shuffle=False, num_workers=2)\n",
    "\n",
    "# Verify the datasets and dataloaders\n",
    "print(f'Training dataset size: {len(train_dataset)}')\n",
    "print(f'Number of batches in training dataloader: {len(train_dataloader)}')\n",
    "print(f'Test dataset size: {len(test_dataset)}')\n",
    "print(f'Number of batches in test dataloader: {len(test_dataloader)}')\n",
    "\n",
    "\n",
    "for images, labels in train_dataloader:\n",
    "    print(f'Batch of images shape: {images.shape}')\n",
    "    print(f'Batch of labels shape: {labels.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justify your preprocessing\n",
    "\n",
    "In your own words, why did you choose the transforms you chose? If you didn't use any preprocessing steps, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DOUBLE CLICK THIS CELL TO MODIFY**\n",
    "I used preprocessing to normalize the dataset to have a mean of 0 and standard deviation of 1 to speed up the training process. I also convereted the image data to PyTorch tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Dataset\n",
    "Using matplotlib, numpy, and torch, explore the dimensions of your data.\n",
    "\n",
    "You can view images using the `show5` function defined below – it takes a data loader as an argument.\n",
    "Remember that normalized images will look really weird to you! You may want to try changing your transforms to view images.\n",
    "Typically using no transforms other than `toTensor()` works well for viewing – but not as well for training your network.\n",
    "If `show5` doesn't work, go back and check your code for creating your data loaders and your training/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell contains a function for showing 5 images from a dataloader – DO NOT CHANGE THE CONTENTS! ##\n",
    "def show5(img_loader):\n",
    "    dataiter = iter(img_loader)\n",
    "    \n",
    "    batch = next(dataiter)\n",
    "    labels = batch[1][0:5]\n",
    "    images = batch[0][0:5]\n",
    "    for i in range(5):\n",
    "        print(int(labels[i].detach()))\n",
    "    \n",
    "        image = images[i].numpy()\n",
    "        plt.imshow(image.T.squeeze().T)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Explore data\n",
    "## YOUR CODE HERE ##\n",
    "show5(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your Neural Network\n",
    "Using the layers in `torch.nn` (which has been imported as `nn`) and the `torch.nn.functional` module (imported as `F`), construct a neural network based on the parameters of the dataset.\n",
    "Use any architecture you like. \n",
    "\n",
    "*Note*: If you did not flatten your tensors in your transforms or as part of your preprocessing and you are using only `Linear` layers, make sure to use the `Flatten` layer in your network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE ##\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Define layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 128)  # First fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 64)     # Second fully connected layer\n",
    "        self.fc3 = nn.Linear(64, 10)      # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)           # Flatten the input tensor\n",
    "        x = F.relu(self.fc1(x))       # Apply ReLU activation after first layer\n",
    "        x = F.relu(self.fc2(x))       # Apply ReLU activation after second layer\n",
    "        x = self.fc3(x)               # Output layer (logits)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SimpleNN()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify a loss function and an optimizer, and instantiate the model.\n",
    "\n",
    "If you use a less common loss function, please note why you chose that loss function in a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##\n",
    "model = SimpleNN()\n",
    "\n",
    "#  loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#  optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running your Neural Network\n",
    "Use whatever method you like to train your neural network, and ensure you record the average loss at each epoch. \n",
    "Don't forget to use `torch.device()` and the `.to()` method for both your model and your data if you are using GPU!\n",
    "\n",
    "If you want to print your loss **during** each epoch, you can use the `enumerate` function and print the loss after a set number of batches. 250 batches works well for most people!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch [1/5], Step [250/938], Loss: 0.0323\n",
      "Epoch [1/5], Step [750/938], Loss: 0.0133\n",
      "Epoch [1/5], Average Loss: 0.0314\n",
      "2\n",
      "Epoch [2/5], Step [250/938], Loss: 0.0245\n",
      "Epoch [2/5], Step [500/938], Loss: 0.0022\n",
      "Epoch [2/5], Step [750/938], Loss: 0.0040\n",
      "Epoch [2/5], Average Loss: 0.0264\n",
      "3\n",
      "Epoch [3/5], Step [250/938], Loss: 0.0079\n",
      "Epoch [3/5], Step [500/938], Loss: 0.0539\n",
      "Epoch [3/5], Step [750/938], Loss: 0.0169\n",
      "Epoch [3/5], Average Loss: 0.0228\n",
      "4\n",
      "Epoch [4/5], Step [250/938], Loss: 0.0029\n",
      "Epoch [4/5], Step [500/938], Loss: 0.0886\n",
      "Epoch [4/5], Step [750/938], Loss: 0.0548\n",
      "Epoch [4/5], Average Loss: 0.0251\n",
      "5\n",
      "Epoch [5/5], Step [500/938], Loss: 0.0074\n",
      "Epoch [5/5], Step [750/938], Loss: 0.0072\n",
      "Epoch [5/5], Average Loss: 0.0182\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Lists to store training loss \n",
    "train_losses = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0    \n",
    "    i+=1\n",
    "    print(i)\n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "      \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update running loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Print loss every 250 batches\n",
    "        if (batch_idx + 1) % 250 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_dataloader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Compute average loss for the epoch\n",
    "    avg_loss = running_loss / len(train_dataloader)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training loss (and validation loss/accuracy, if recorded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT0AAAFNCAYAAAByubhcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzP0lEQVR4nO3deXwV9fX/8dfJQsISAoSwBkgiCAaCIGEPFbVacAEsWkFQUHCriFZbl/antdpFv19bK9+6FFmLilBX3Kp1ZZMl7LsgBAkohABhJyQ5vz/uBGMMkOVO5i7n+Xjkwb1zPzP3DMubuXc+c0ZUFWOMCRcRXhdgjDE1yULPGBNWLPSMMWHFQs8YE1Ys9IwxYcVCzxgTViz0TEARkQ9EZJS/xxpTQmyenqkuETlc6mkd4ARQ5Dy/TVVfrvmqqk5E+gMvqWqSx6UYF0R5XYAJfqpar+SxiGQDY1X147LjRCRKVQtrsjZjyrKPt8Y1ItJfRHJE5AER+Q6YKiINReRdEckVkf3O46RS63wuImOdx6NFZL6IPOWM3SYiA6s4NkVE5orIIRH5WESeFZGXqrBP5znve0BE1onIoFKvXS4i65332Ckiv3aWN3b284CI7BOReSJi//Y8Yr/xxm3NgEZAG+BWfH/npjrPWwPHgH+cYf2ewCagMfA/wGQRkSqMfQVYAiQAjwI3VHZHRCQaeAf4CGgC3AW8LCLtnSGT8X2cjwM6AZ86y+8DcoBEoCnwW8C+V/KIhZ5xWzHwe1U9oarHVDVPVV9X1aOqegj4E3DhGdbfrqovqmoRMB1oji84KjxWRFoD3YFHVLVAVecDc6qwL72AesATznY+Bd4FhjuvnwTSRKS+qu5X1eWlljcH2qjqSVWdp/Zlumcs9IzbclX1eMkTEakjIv8Uke0ichCYCzQQkcjTrP9dyQNVPeo8rFfJsS2AfaWWAeyo5H7gbGeHqhaXWrYdaOk8HgpcDmwXkS9EpLez/H+BLcBHIrJVRB6swnsbP7HQM24re0RzH9Ae6Kmq9YGfOMtP95HVH74FGolInVLLWlVhO7uAVmW+j2sN7ARQ1aWqOhjfR9+3gNnO8kOqep+qpgKDgHtF5JIqvL/xAws9U9Pi8H2Pd0BEGgG/d/sNVXU7kAU8KiK1nCOwq862nojElv7B953gUeB+EYl2prZcBbzqbHeEiMSr6kngIL6P9ojIlSLS1vl+MR/fdJ7i8t7TuM9Cz9S0vwO1gb3AIuA/NfS+I4DeQB7wR2AWvvmEp9MSXziX/mmFL+QG4qv/OeBGVd3orHMDkO18bL/deU+AdsDHwGHgS+A5Vf3Mb3tmKsUmJ5uwJCKzgI2q6vqRpgksdqRnwoKIdBeRc0QkQkQGAIPxfe9mwoyroSciA0Rkk4hsKe+MlYjEiMgs5/XFIpLsLO8hIiudn1UicrWzvJWIfOZMAF0nIne7Wb8JKc2Az/F9xJwA3KGqKzytyHjCtY+3zhSEr4BL8U3MXAoMV9X1pcb8EuisqreLyDDgalW9zjnLVqCqhSLSHFiFb7pAItBcVZeLSBywDBhSepvGGHMmbh7p9QC2qOpWVS0AXsX3kaK0wfgmkQK8BlwiIuJMXC25RjMWZ9qDqn5bMuHTmdi6ge/nSBljzFm5GXot+eEE0Bx+HFCnxjghl4/vMiFEpKeIrAPWALeXvVDd+SjcFVjsRvHGmNAUsF1WVHUx0FFEzgOmi8gHJTP7RaQe8Dpwj6oeLG99EbkV37We1K1bt1uHDh1qqHJjjNeWLVu2V1UTy3vNzdDbyQ9nvSc5y8obkyMiUUA8vnlUp6jqBvH1a+sEZDkXfb8OvKyqb5zuzVV1IjARICMjQ7Oysqq5O8aYYCEi20/3mpsfb5cC7ZyWPrWAYfz4Iu85QEnn22uAT1VVnXWiAESkDdAB36RPwdfJYoOq/s3F2o0xIcq1Iz3nzOs44EMgEpiiqutE5DEgS1Xn4AuwGSKyBdiHLxgBMoEHReQkvst1fqmqe0UkE9+s9zUistIZ+1tVfd+t/TDGhJawuCLDPt4aE15EZJmqZpT3WsCeyDAmUJ08eZKcnByOHz9+9sHGVbGxsSQlJREdHV3hdSz0jKmknJwc4uLiSE5O5vRNnI3bVJW8vDxycnJISUmp8Hp27a0xlXT8+HESEhIs8DwmIiQkJFT6iNtCz5gqsMALDFX5c7DQMybI5OXl0aVLF7p06UKzZs1o2bLlqecFBQVnXDcrK4vx48ef9T369Onjl1o///xzrrzySr9sy1/sOz1jgkxCQgIrV64E4NFHH6VevXr8+te/PvV6YWEhUVHl/9POyMggI6Pck5o/sHDhQr/UGojsSK+UHfuOMnPJN16XYUyljR49mttvv52ePXty//33s2TJEnr37k3Xrl3p06cPmzZtAn545PXoo49y8803079/f1JTU5kwYcKp7dWrV+/U+P79+3PNNdfQoUMHRowYQck0t/fff58OHTrQrVs3xo8fX6kjupkzZ5Kenk6nTp144IEHACgqKmL06NF06tSJ9PR0nn76aQAmTJhAWloanTt3ZtiwYWfabIXYkV4p0xZmM2XBNs5rXp8urRp4XY4xlZKTk8PChQuJjIzk4MGDzJs3j6ioKD7++GN++9vf8vrrr/9onY0bN/LZZ59x6NAh2rdvzx133PGj6R8rVqxg3bp1tGjRgr59+7JgwQIyMjK47bbbmDt3LikpKQwfPvxH2z6dXbt28cADD7Bs2TIaNmzIZZddxltvvUWrVq3YuXMna9euBeDAgQMAPPHEE2zbto2YmJhTy6rDQq+Ue37ajndW7eJ3b67h7Tv7EhVpB8LmzP7wzjrW7yq350WVpbWoz++v6ljp9a699loiI3130szPz2fUqFFs3rwZEeHkyZPlrnPFFVcQExNDTEwMTZo0Yffu3SQlJf1gTI8ePU4t69KlC9nZ2dSrV4/U1NRTU0WGDx/OxIkTK1Tn0qVL6d+/P4mJvn4AI0aMYO7cuTz88MNs3bqVu+66iyuuuILLLrsMgM6dOzNixAiGDBnCkCFDKv37Upb9qy4lLjaaR65KY92ug8xYdNrrlY0JSHXr1j31+OGHH+aiiy5i7dq1vPPOO6ed1hETE3PqcWRkJIWFhVUa4w8NGzZk1apV9O/fnxdeeIGxY8cC8N5773HnnXeyfPlyunfvXu33tyO9Mq5Ib86sdjv460dfcXl6c5rWj/W6JBPAqnJEVhPy8/Np2dLXvnLatGl+33779u3ZunUr2dnZJCcnM2vWrAqv26NHD8aPH8/evXtp2LAhM2fO5K677mLv3r3UqlWLoUOH0r59e0aOHElxcTE7duzgoosuIjMzk1dffZXDhw/ToEGDKtduR3pliAiPD+5EQVExj71rXehNcLr//vt56KGH6Nq1qytHZrVr1+a5555jwIABdOvWjbi4OOLj48sd+8knn5CUlHTqJzs7myeeeIKLLrqI888/n27dujF48GB27txJ//796dKlCyNHjuQvf/kLRUVFjBw5kvT0dLp27cr48eOrFXhgDQdO65mPN/P0x18x/eYeXHhuub0ITZjasGED5513ntdleO7w4cPUq1cPVeXOO++kXbt2/OpXv6rxOsr78zhTwwE70juN2/unktq4Lo+8vZbjJ4u8LseYgPPiiy/SpUsXOnbsSH5+PrfddpvXJVWIhd5pxERF8viQTmzPO8pzn23xuhxjAs6vfvUrVq5cyfr163n55ZepU6eO1yVViIXeGfRt25jBXVrwwhdb+Tr3sNflGGP8wELvLH53xXnEREfw8FtrCYfvP03F2N+FwFCVPwcLvbNoEhfL/T9rz8Kv85izapfX5ZgAEBsbS15engWfx0r66cXGVm5amc3Tq4Dre7bh38tyePzd9fRv34T42hXv0mpCT1JSEjk5OeTm5npdStgr6ZxcGRZ6FRAZIfxpSDqDn53PUx9u4vEhnbwuyXgoOjq6Up16TWCxj7cVlJ4Uz429k3lp8XZW7jjgdTnGmCqy0KuEey87l8R6MfzuzTUUFhV7XY4xpgos9Cqhfmw0D19pDQmMCWYWepV0Zefm9GvXmL9+9BW7D9otAI0JNhZ6lWQNCYwJbhZ6VZDcuC539m/Le6u/5YuvbNqCMcHEQq+KrCGBMcHJQq+KftCQ4POvvS7HGFNBFnrVcKohwedfs9UaEhgTFFwNPREZICKbRGSLiDxYzusxIjLLeX2xiCQ7y3uIyErnZ5WIXF3Rbda0Uw0J3raGBMYEA9dCT0QigWeBgUAaMFxE0soMGwPsV9W2wNPAk87ytUCGqnYBBgD/FJGoCm6zRpU0JFiwxRoSGBMM3DzS6wFsUdWtqloAvAoMLjNmMDDdefwacImIiKoeVdWSxv6xQMkhVEW2WeOu79mGzknxPP7uBvKPlX+rPWNMYHAz9FoCO0o9z3GWlTvGCbl8IAFARHqKyDpgDXC783pFtlnjShoS7Dtygqc+3OR1OcaYMwjYExmqulhVOwLdgYdEpFJNs0TkVhHJEpGsmmgBVLohwSprSGBMwHIz9HYCrUo9T3KWlTtGRKKAeCCv9ABV3QAcBjpVcJsl601U1QxVzSi5k7rbTjUkeGsNRcV2UsOYQORm6C0F2olIiojUAoYBc8qMmQOMch5fA3yqquqsEwUgIm2ADkB2BbfpmZKGBGt3HmTGl9lel2OMKYdroed8BzcO+BDYAMxW1XUi8piIDHKGTQYSRGQLcC9QMgUlE1glIiuBN4Ffqure023TrX2oipKGBE9ZQwJjApLd7NsF2XuPcNnf53JZWlP+cf0FNfa+xhgfu9l3DStpSPDu6m+Zaw0JjAkoFnouub1/KimN6/KwNSQwJqBY6LkkJiqSxwdbQwJjAo2Fnosy2zVm0PnWkMCYQGKh57L/d6U1JDAmkFjouaxJXCy/sYYExgQMC70aMMIaEhgTMCz0akDphgR//cgaEhjjJQu9GlLSkGDGImtIYIyXLPRq0L2XnUtja0hgjKcs9GpQ/dhoHrGGBMZ4ykKvhllDAmO8ZaFXw0SExwZ3oqComMffXe91OcaEHQs9D6Q0rssv+59jDQmM8YCFnkduv/AcUhrX5RFrSGBMjbLQ80hstK8hQXbeUZ63hgTG1BgLPQ+VNCR43hoSGFNjLPQ89v+uPI+YqAgeeXudNSQwpgZY6HmsSVwsvxnQnvlb9lpDAmNqgIVeAChpSPDH96whgTFus9ALACUNCfIOW0MCY9xmoRcgSjckWJ1zwOtyjAlZFnoB5FRDgjfXWkMCY1xioRdAShoSrNmZz0uLtntdjjEhyUIvwJxqSPDhJvZYQwJj/M5CL8CUNCQ4UVTM4+9t8LocY0KOhV4AKmlI8M6qXdaQwBg/s9ALUNaQwBh3WOgFKGtIYIw7XA09ERkgIptEZIuIPFjO6zEiMst5fbGIJDvLLxWRZSKyxvn14lLrDHeWrxaR/4hIYzf3wUvWkMAY/3Mt9EQkEngWGAikAcNFJK3MsDHAflVtCzwNPOks3wtcparpwChghrPNKOAZ4CJV7QysBsa5tQ+BwBoSGONfbh7p9QC2qOpWVS0AXgUGlxkzGJjuPH4NuERERFVXqGrJ1ffrgNoiEgOI81NXRASoD4T0VfrWkMAY/3Iz9FoCO0o9z3GWlTtGVQuBfCChzJihwHJVPaGqJ4E7gDX4wi4NmFzem4vIrSKSJSJZubnBfQbUGhIY4z8BfSJDRDri+8h7m/M8Gl/odQVa4Pt4+1B566rqRFXNUNWMxMTEGqrYHdaQwBj/cTP0dgKtSj1PcpaVO8b5vi4eyHOeJwFvAjeqasnpyy4Aqvq1+r7gmg30can+gJKeFM8NvdpYQwJjqsnN0FsKtBORFBGpBQwD5pQZMwffiQqAa4BPVVVFpAHwHvCgqi4oNX4nkCYiJYdulwJhc9nCfT9rbw0JjKkm10LP+Y5uHPAhvmCararrROQxERnkDJsMJIjIFuBeoGRayzigLfCIiKx0fpo4Jzf+AMwVkdX4jvz+7NY+BJr6sdE8bA0JjKkWCYdpEBkZGZqVleV1GX6hqtw4ZQkrvznAJ/ddSJP6sV6XZEzAEZFlqppR3msBfSLD/Jg1JDCmeiz0glDphgTzNgf3dBxjapqFXpC6/cJzSE6ow8NvWUMCYyrDQi9IxUZH8vgQa0hgTGVZ6AWxfu0SucppSLBt7xGvyzEmKFjoBbmHr/A1JHj4rbXWkMCYCrDQC3JN6sfy65/5GhK8s/pbr8sxJuBZ6IWAkb3akN4ynsffXc/B49aQwJgzsdALAZERwp+u7sTewyf464fWkMCYM7HQCxGdkxpwY682/MsaEhhzRhZ6IcQaEhhzdhZ6IcQaEhhzdhZ6Ieaqzs3JbNuYpz7cxJ6Dx70ux5iAY6EXYkSEx4dYQwJjTsdCLwSlNK7LHRdaQwJjymOhF6Lu6G8NCYwpj4VeiCrdkOCFL6whgTElLPRCWElDguc+s4YExpSw0AtxJQ0JHnnbGhIYAxZ6Ia+kIcG8zdaQwBiw0AsL1pDAmO9Z6IUBa0hgzPcs9MJESUOCGdaQwIQ5C70wct/P2pNgDQlMmLPQCyOlGxJMXbDN63KM8YSFXpi5qnNzfnpeE/7ywUY+37TH63KMqXEWemFGRPj7sK60bxrHnS8vZ/2ug16XZEyNstALQ/Viopgyujv1a0dz87SlfJt/zOuSjKkxroaeiAwQkU0iskVEHizn9RgRmeW8vlhEkp3ll4rIMhFZ4/x6cal1aonIRBH5SkQ2ishQN/chVDWLj2XK6O4cPlHITVOXcsjm75kw4VroiUgk8CwwEEgDhotIWplhY4D9qtoWeBp40lm+F7hKVdOBUcCMUuv8Dtijquc62/3CrX0Idec1r89zIy5g857D3PnKCk4WFXtdkjGuc/NIrwewRVW3qmoB8CowuMyYwcB05/FrwCUiIqq6QlV3OcvXAbVFJMZ5fjPwFwBVLVbVvS7uQ8j7ybmJ/GlIJ+Z+lWvX55qw4GbotQR2lHqe4ywrd4yqFgL5QEKZMUOB5ap6QkQaOMseF5HlIvJvEWnq98rDzLAerbnzonOYuWQHL3yx1etyjHFVQJ/IEJGO+D7y3uYsigKSgIWqegHwJfDUada9VUSyRCQrN9e6B5/NfZe2Z9D5LXjyPxuZs2rX2VcwJki5GXo7gValnic5y8odIyJRQDyQ5zxPAt4EblTVki6YecBR4A3n+b+BC8p7c1WdqKoZqpqRmJhY/b0JcRERwv9e25keyY349exVLM3e53VJxrjCzdBbCrQTkRQRqQUMA+aUGTMH34kKgGuAT1VVnY+x7wEPquqCksHq+8LpHaC/s+gSYL1rexBmYqIi+ecN3UhqWJtb/pXF1tzDXpdkjN+5FnrOd3TjgA+BDcBsVV0nIo+JyCBn2GQgQUS2APcCJdNaxgFtgUdEZKXz08R57QHgURFZDdwA3OfWPoSjhnVrMe2mHkSKcNO0peQdPuF1Scb4lYTD2bqMjAzNysryuoygsvyb/QyfuIiOLerzyi29iI2O9LokYypMRJapakZ5rwX0iQzjnQtaN+Tv13VhxY4D3Dt7JcXWlcWECAs9c1oD05vzu8vP4/013/HkfzZ6XY4xfhHldQEmsI3JTOGbfUf559ytJDWqww292nhdkjHVYqFnzkhEeOTKNHbuP8bv315LUoPaXNShydlXNCZA2cdbc1ZRkRFMGN6VtBb1ufOV5azdme91ScZUmYWeqZC6MVFMGdWdBk47ql0HrB2VCU4WeqbCmtSPZepNPThWUMRNU5fa7SRNULLQM5XSvlkcz4/sxte5h/nlS8utHZUJOhZ6ptIy2zXmLz9PZ/6WvfzuzTXWjsoElQqdvRWRusAxVS0WkXOBDsAHqmqfb8LUtRmt2LH/GBM+2UzrRnUYd3E7r0sypkIqeqQ3F4gVkZbAR/iueZ3mVlEmOPzqp+34edeWPPXRV7y1omwDHWMCU0VDT1T1KPBz4DlVvRbo6F5ZJhiICE8M7Uyv1Ebc/9pqFm3N87qksLN2Zz6fbbRbeVZGhUNPRHoDI/C1fAKwK9ANtaIi+OfIDFo1qs1tM5axZY+1o6oJxcXK859/zZBnFzD2X1k2hagSKhp69wAPAW867aFSgc9cq8oElfg60Uy7qQfRkcJN05aw19pRuSr30AlGTV3Ck//ZyIXn+hrkTl+Y7W1RQaRCoaeqX6jqIFV9UkQigL2qOt7l2kwQadWoDpNGdSf30AnGTs/iWEGR1yWFpHmbcxn4zDyWbNvHn69OZ9KoDAZ0asYrS77h8IlCr8sLChUKPRF5RUTqO2dx1wLrReQ37pZmgk2XVg14ZlhXVuUc4J5ZKyiydlR+c7KomCc+2MgNk5fQqG40c8Zlcn3P1ogIt/RL5dDxQmYv3XH2DZkKf7xNU9WDwBDgAyAF3xlcY37gZx2b8fAVaXy4bjd/eX+D1+WEhB37jnLtC1/ywhdfc33P1rx9Zybtm8Wder1LqwZktGnIlAXb7D+aCqho6EWLSDS+0JvjzM+z311TrpszUxjdJ5lJ87fZd03V9O7qXVz+zDy+zj3Ms9dfwJ+vTqd2rR+fQxzbL4Wc/cf4aN13HlQZXCoaev8EsoG6wFwRaQMcdKsoE/wevjKNS9Oa8od31vHf9bu9LifoHCso4qE3VjPulRW0bVqP98f344rOzU87/tK0ZrRqVJtJ87fVYJXBqaInMiaoaktVvVx9tgMXuVybCWKREcIzw7qQ3jKe8TNXsDrngNclBY1N3x1i0D/m8+rSHdzR/xxm39abVo3qnHGdyAjh5r4pLNu+n+Xf7K+hSoNTRU9kxIvI30puni0if8V31GfMadWpFcWkUd1JqFeLm6dlkbP/qNclBTRV5eXF2xn0j/nsP3qSf93cgwcGdCA6smIfyH6R0Yq42Cgmz7OjvTOp6MfbKcAh4BfOz0FgqltFmdCRGBfDtJu6U1Doa0eVf8wu1y5P/rGT/PLl5fzuzbX0TE3gg7v70a9d5W5SXzcmiut7tuaDtd+yY5/9B3M6FQ29c1T196q61fn5A5DqZmEmdLRtEscLN3QjO+8Id7y0jIJCa0dV2rLt+7n8mXn8d/1uHhrYgWmju5MYF1OlbY3uk0yECNPsBNJpVTT0jolIZskTEekL2HUvpsL6nNOYJ4d2ZuHXeTz0hrWjAt+lZM9+toVf/PNLIiLg37f35rYLzyEiQqq8zebxtbmic3NmLd1hTV5Po6I3Brod+JeIxDvP9wOj3CnJhKqfX5DEjn3HePrjr2jdqA53/zR821HtOXSce2etYv6WvVzZuTl//nk69WOj/bLtsZmpvL1yF7OW7OCWn9gHsrIqFHqqugo4X0TqO88Pisg9wGoXazMhaPwlbflm31Ge/vgrkhrWZmi3JK9LqnGfb9rDfbNXcaSgkCeHpvOLjFaIVP3orqz0pHh6pjRi6oJt3NQ3magKnggJF5X63VDVg86VGQD3ulCPCXEiwl9+nk6fcxJ48I3VLPx6r9cl1ZiCwmL+/P4GRk9dSmJcDO+My+S67q39GnglxvZLZVf+cT5Ya5OVy6rOfwH+/5MyYaFWVATPj+xGckJdbpuxjM27D3ldkuu+yTvKtS8sZOLcrYzs1Zq37uxLu6ZxZ1+xii7p0ISUxnWZNG+rfX9aRnVCz34nTZXF145m6k3diY2OZPTUpew5dNzrklwzZ9Uurpgwj217j/D8iAv445B0YqPdbUcZESHcnJnCqpx8srbbZOXSzhh6InJIRA6W83MIaHG2jYvIABHZJCJbROTBcl6PEZFZzuuLRSTZWX6piCwTkTXOrxeXs+4cEVlb8V01gSapYR0mj8pg35ECxk7P4mhBaLVGOlpQyAOvrWb8zBWc2yyO9+/ux8D0019K5m9DL2hJgzrRTJq3tcbeMxicMfRUNU5V65fzE6eqZzwJIiKRwLPAQCANGC4iaWWGjQH2q2pb4GngSWf5XuAqVU3Hd5Z4Rplt/xywFr0hoHNSA/5veFfW7sxn/MyVIdMlZMO3B7nq/+Yze9kOxl3Ullm39iKp4ZkvJfO3OrWiGNGzNR+t3832vCM1+t6BzM3TOj2ALc5k5gLgVWBwmTGDgenO49eAS0REVHWFqu5ylq8DaotIDICI1MN3EuWPLtZuatBP05ry6KCOfLxhN4+/u97rcqpFVZnxZTaDn13AweOFvDSmJ7/+WXvPzqDe2DuZqAhh6oJsT94/ELn5J9ESKN3VMMdZVu4YVS0E8oGEMmOGAstVtaQH+ePAXwG7ziaE3Ng7mbGZKUxbmM2UIO0Ukn/0JLe/tIyH315Hn3N8l5L1bdvY05qa1o/lqvNbMDtrB/lHbbIyBPjNvkWkI76PvLc5z7vguyTuzQqse2tJg4Tc3Fx3CzV+8dvLz2NAx2Y8/t56PgyyvnBZ2fu4fMI8Pt24h99dfh5TRnWncb2qXUrmb2MzUzlaUMQrS77xupSA4Gbo7QRalXqe5Cwrd4yIRAHxQJ7zPAl4E7hRVb92xvcGMkQkG5gPnCsin5f35qo6UVUzVDUjMbFyF24bb0RECE9f14Xzkxpw96srWLnjgNclnVVRsfKPTzdz3cRFREYIr93eh1t+klqtS8n8La1Fffq2TWDawm123TPuht5SoJ2IpIhILWAYMKfMmDl8fznbNcCnqqoi0gDfrSYfVNUFJYNV9XlVbaGqyUAm8JWq9ndxH0wNq10rkkmjMkiMi2Hs9KUB3S1k98HjjJy0mKc++oor0pvz3vhMzm/VwOuyyjU2M5XdB0/w/ppvvS7Fc66FnvMd3TjgQ2ADMNu5feRjIjLIGTYZSBCRLfhOTpRMaxkHtAUeEZGVzk8Tt2o1gaVxvRimju7BySJl9NQlAfld1Gcb9zDwmXms3HGA/7mmM88M60Kcn66ddcOF5yZyTmJdJs23ycoSDr8BGRkZmpWV5XUZppIWb83jhslLuKBNA6bf3IOYKO/vL19QWMz//Gcjk+Zvo0OzOP5x/QW0bVLP67IqZOaSb3jojTXMvKUXvc8pe74wtIjIMlXNKO+1gD6RYcJbz9QE/vfazizauo8HX/e+HVX23iNc88JCJs3fxo292/DWnX2DJvAAru7akkZ1azF5fnhPVq5oayljPDG4S0t27DvKUx99RatGdbj30nM9qePtlTv57RtriIqM4J83dONnHZt5Ukd1xEZHMrJXGyZ8spmtuYdJTQyewPYnO9IzAe/Oi9pyXUYrJnyymdlZNXtD66MFhfzm36u4+9WVpLWoz/t39wvKwCtxQ6821IqMYMqC4JwL6Q8WeibgiQh/vLoT/do15rdvrGH+5pppR7VuVz5X/t98Xluew/iL2zLzll60bFC7Rt7bLYlxMQzp2oLXluWw/0iB1+V4wkLPBIXoyAieHeE7aXDHS8vY9J177ahUlekLs7n6uYUcOVHIy2N7cu9l3l1K5m9j+6Vy/GQxLy/e7nUpngiNP0UTFurHRjNldHdq14rkpqlL2H3Q/+2oDhwt4NYZy/j9nHVktm3M++P70eccby8l87dzm8bxk3MTmf7ldk4UFnldTo2z0DNBpUWD2kwZ3Z0Dx04yZvpSjpzwXzuqJdv2MfCZeXy+aQ8PX5nG5FEZJATIpWT+NjYzhdxDJ3hnVfhNVrbQM0GnU8t4nr3+AtbvOshdM1dQWFS9S6uKipUJn2xm2MQviYmK4I07+jImM8WVNu6Bol+7xrRvGheWnZUt9ExQuqhDEx4b3IlPN+7hD++sr/I/3O/yjzNi0iL+9t+vGNylJe+O70d6UvzZVwxyIsKYfils/O4QC7bkeV1OjbLQM0FrZK823PaTVGYs2s7kKrSj+mTDbgY+M5fVOfn89drzefq6LtSLCZ+pq4O7tKBxvRgmhdlkZQs9E9QeGNCBy9Ob8af3N/BBBS+mP1FYxGPvrGfM9Cyax9fmnbsyw/JWlDFRkdzYuw2fb8oNi5szlbDQM0EtIkL42y+60LVVA+6ZtZLl35z5Jjjb9h5h6PMLmbJgG6P7JPPGL/twTphemQAwomdrYqLCa7KyhZ4JerHRkbx4YwbN4mO5ZXrWae8H8eaKHK6cMI+c/cd48cYMHh3U0fW7kgW6hHoxDO2WxOvLd5J3+MTZVwgBFnomJCTUi2Hq6O4UqXLT1KU/uNrgyIlC7p29kl/NWkXHlvF8cHc/Lk1r6mG1geXmvikUFBYzY1F4TFa20DMhIzWxHpNuzCDnwDFunZHF8ZNFrN3pu5TsrRU7ueen7Zh5Sy+axwf3pWT+1rZJPS7u0IQZX27n+MnQn6xsoWdCSkZyI/567fkszd7P8BcX8fPnFnKsoIhXbunFPT89l8gAauMeSMZmppB3pIC3V5a9o0PosdAzIeeq81vwwIAOrPjmAD85tzHv392PXqmh3TSzunqfk8B5zeszad62kJ+sHD6TkkxYuf3CVAZ0akZyQp2QvrLCX0SEW/qlcO/sVXzxVS7924fu3RnsSM+EJBEhpXFdC7xKuLJzC5rExVRponcwsdAzxgBQKyqCUX2Smbd5Lxu/O+h1Oa6x0DPGnDKiZ2tqR0cyeV7oHu1Z6BljTmlQpxbXZiTx9spd7Dnk/36FgcBCzxjzAzf1TeFkcTEzvgzNycoWesaYH0hpXJefnteUlxZt51hB6E1WttAzxvzI2MwU9h89yRsrcrwuxe8s9IwxP9IjpRGdk+KZPH8bxcWhNVnZQs8Y8yMiwpjMFLbmHuGzTXu8LsevLPSMMeW6PL05zeNjmRRi01dcDT0RGSAim0Rki4g8WM7rMSIyy3l9sYgkO8svFZFlIrLG+fViZ3kdEXlPRDaKyDoRecLN+o0JZ9GREYzuk8yXW/NYuzPf63L8xrXQE5FI4FlgIJAGDBeRtDLDxgD7VbUt8DTwpLN8L3CVqqYDo4AZpdZ5SlU7AF2BviIy0K19MCbcDevRmrq1IpkSQpemuXmk1wPYoqpbVbUAeBUYXGbMYGC68/g14BIREVVdoaq7nOXrgNoiEqOqR1X1MwBnm8uB8Lu5gTE1JL52NL/o3oo5q3bxXX5oTFZ2M/RaAjtKPc9xlpU7RlULgXygbA+gocByVf1BL2sRaQBcBXziv5KNMWXd1CeFYlWmf5ntdSl+EdAnMkSkI76PvLeVWR4FzAQmqGq5968TkVtFJEtEsnJzc90v1pgQ1TqhDj/r2IyXF23nyIlCr8upNjdDbyfQqtTzJGdZuWOcIIsH8pznScCbwI2q+nWZ9SYCm1X176d7c1WdqKoZqpqRmJhYnf0wJuyN7ZfCweOFvL48+Ccruxl6S4F2IpIiIrWAYcCcMmPm4DtRAXAN8KmqqvPR9T3gQVVdUHoFEfkjvnC8x8XajTGldGvTiK6tGzBl/jaKgnyysmuh53xHNw74ENgAzFbVdSLymIgMcoZNBhJEZAtwL1AyrWUc0BZ4RERWOj9NnKO/3+E7G7zcWT7WrX0wxnxvbGYq2XlH+WTDbq9LqRYJ9X74ABkZGZqVleV1GcYEtcKiYi78389p2aA2s2/v7XU5ZyQiy1Q1o7zXAvpEhjEmcERFRnBT32SWZO9j1Y4DXpdTZRZ6xpgKu657K+JiooL6PhoWesaYCouLjWZYj1a8t+Zbdh045nU5VWKhZ4yplFF9kgGYtjDb0zqqykLPGFMpSQ3rMLBTM2Yu/obDQThZ2ULPGFNpY/ulcuhEIbOX7jj74ABjoWeMqbQurRrQPbkhUxYE32RlCz1jTJWMyUwlZ/8xPlr3ndelVIqFnjGmSi5Na0rrRnV4cV65PT8CloWeMaZKIiOEm/sms/ybAyzbvt/rcirMQs8YU2XXZrSifmxUUHVWttAzxlRZ3Zgoru/Zhg/WfsuOfUe9LqdCLPSMMdUyqk8bIkSYuiDb61IqxELPGFMtzeNrc2Xn5sxa+g0Hj5/0upyzstAzxlTb2H6pHCkoYtaSwJ+sbKFnjKm2Ti3j6ZXaiKkLtlFYVOx1OWdkoWeM8Yuxmansyj/OB2sDe7KyhZ4xxi8u7tCElMZ1mTRvK4Hckd1CzxjjFxERws2ZKazKyScrgCcrW+gZY/zmmguSaFAnmkkBfGmahZ4xxm9q14pkZM82fLR+N9vzjnhdTrks9IwxfnVj7zZERUjAXppmoWeM8asm9WMZdH5LZmflkH808CYrW+gZY/xuTGYKx04W8cqSb7wu5Ucs9IwxfpfWoj6ZbRszbeE2CgoDa7KyhZ4xxhVj+qWw++AJ3l/zrdel/ICFnjHGFRe2S6Rtk3q8GGCTlS30jDGuiIgQxmSmsG7XQRZt3ed1OadY6BljXHN115Yk1K3F5PmBM1nZ1dATkQEisklEtojIg+W8HiMis5zXF4tIsrP8UhFZJiJrnF8vLrVON2f5FhGZICLi5j4YY6ouNjqSkb3a8PGGPWzNPex1OYCLoScikcCzwEAgDRguImllho0B9qtqW+Bp4Eln+V7gKlVNB0YBM0qt8zxwC9DO+Rng1j4YY6pvZK821IqKYHKATFZ280ivB7BFVbeqagHwKjC4zJjBwHTn8WvAJSIiqrpCVXc5y9cBtZ2jwuZAfVVdpL5vRv8FDHFxH4wx1ZQYF8PVXVry+vIc9h0p8LocV0OvJVC6jWqOs6zcMapaCOQDCWXGDAWWq+oJZ3zOWbZpjAkwY/qlcPxkMa8s3u51KYF9IkNEOuL7yHtbFda9VUSyRCQrNzfX/8UZYyrs3KZxXHhuItO/3M6JwiJPa3Ez9HYCrUo9T3KWlTtGRKKAeCDPeZ4EvAncqKpflxqfdJZtAqCqE1U1Q1UzEhMTq7krxpjqGtsvhdxDJ3hnlbeTld0MvaVAOxFJEZFawDBgTpkxc/CdqAC4BvhUVVVEGgDvAQ+q6oKSwar6LXBQRHo5Z21vBN52cR+MMX6S2bYx7ZvGed5Z2bXQc76jGwd8CGwAZqvqOhF5TEQGOcMmAwkisgW4FyiZ1jIOaAs8IiIrnZ8mzmu/BCYBW4CvgQ/c2gdjjP+ICGP6pbDxu0Ms2JLnXR2BdHmIWzIyMjQrK8vrMowJeycKi+j7xGd0almfaTf1cO19RGSZqmaU91pAn8gwxoSWmKhIRvVuw+ebctm8+5AnNVjoGWNq1IhebYjxcLKyhZ4xpkY1qluLod2SeGPFTvYePlHj72+hZ4ypcWMyUygoLOalRTU/WdlCzxhT485JrMclHZow48vtHD9Zs5OVLfSMMZ4Y0y+FvCMFvL2y3OsLXGOhZ4zxRO/UBNKa12fSvG01OlnZQs8Y4wkR4ZafpLB5z2G++Krmro+30DPGeOaK9BY0rR9To9NXLPSMMZ6pFRXBqD7JzNu8l43fHayR97TQM8Z46voerakdHcmkeTVztGehZ4zxVIM6tbg2I4m3V+5kz8Hjrr+fhZ4xxnM3902hsFiZUQOTlS30jDGeS25cl0vPa8pLi7ZzrMDdycoWesaYgDC2Xyr7j57kjRU5Zx9cDRZ6xpiA0D25IZ2T4pk8bxvFxe5NVrbQM8YEBBFhbL9Utu49wmeb9rj2PhZ6xpiAMbBTM1rEx7o6fcVCzxgTMKIjIxjdN5kvt+axdme+K+9hoWeMCSjXdW9N3VqRrl2aZqFnjAko8bWj+UX3Vryzahff5ft/srKFnjEm4NzcN4ViVaZ/me33bVvoGWMCTqtGdRjQqRkvL9rOkROFft22hZ4xJiCNyUzl4PFCXl/u38nKFnrGmIDUrU1DurZuwOT52yjy42RlCz1jTMC6pV8q2/OO8vGG3X7bpoWeMSZgXZbWlKSGtZnsx8nKFnrGmIAVFRnBTX1TWJK9j1U7DvhlmxZ6xpiA9ouMJOJionhl8Td+2Z6roSciA0Rkk4hsEZEHy3k9RkRmOa8vFpFkZ3mCiHwmIodF5B9l1hkuImtEZLWI/EdEGru5D8YYb8XFRjN9TA8eHdTRL9tzLfREJBJ4FhgIpAHDRSStzLAxwH5VbQs8DTzpLD8OPAz8usw2o4BngItUtTOwGhjn1j4YYwLDBa0bUrtWpF+25eaRXg9gi6puVdUC4FVgcJkxg4HpzuPXgEtERFT1iKrOxxd+pYnzU1dEBKgP7HJtD4wxIcfN0GsJ7Cj1PMdZVu4YVS0E8oGE021QVU8CdwBr8IVdGjC5vLEicquIZIlIVm5uzd1I2BgT2ILqRIaIROMLva5AC3wfbx8qb6yqTlTVDFXNSExMrMEqjTGBzM3Q2wm0KvU8yVlW7hjn+7p4IO8M2+wCoKpfq6oCs4E+fqrXGBMG3Ay9pUA7EUkRkVrAMGBOmTFzgFHO42uAT50wO52dQJqIlBy6XQps8GPNxpgQF+XWhlW1UETGAR8CkcAUVV0nIo8BWao6B9/3cTNEZAuwD18wAiAi2fhOVNQSkSHAZaq6XkT+AMwVkZPAdmC0W/tgjAk9cuYDq9CQkZGhWVlZXpdhjKkhIrJMVTPKey2oTmQYY0x1WegZY8KKhZ4xJqyExXd6IpKL76RHRTQG9rpYTqCw/Qwd4bCPULn9bKOq5U7QDYvQqwwRyTrdF6ChxPYzdITDPoL/9tM+3hpjwoqFnjEmrFjo/dhErwuoIbafoSMc9hH8tJ/2nZ4xJqzYkZ4xJqxY6JVytvb2oUBEpojIHhFZ63UtbhGRVs7tBtaLyDoRudvrmtwgIrEiskREVjn7+Qeva3KLiESKyAoRebe627LQc1SwvX0omAYM8LoIlxUC96lqGtALuDNE/yxPABer6vn42q4NEJFe3pbkmrvxU0clC73vVaS9fdBT1bn4OtqELFX9VlWXO48P4fvHUrZrd9BTn8PO02jnJ+S+pBeRJOAKYJI/tmeh972KtLc3Qca5w15XYLHHpbjC+di3EtgD/FdVQ3E//w7cDxT7Y2MWeiZkiUg94HXgHlU96HU9blDVIlXtgq8zeQ8R6eRxSX4lIlcCe1R1mb+2aaH3vYq0tzdBwrmfyuvAy6r6htf1uE1VDwCfEXrf1/YFBjlNhV8FLhaRl6qzQQu971Wkvb0JAs7tQScDG1T1b17X4xYRSRSRBs7j2vhun7DR06L8TFUfUtUkVU3G92/yU1UdWZ1tWug5nFtQlrS33wDMVtV13lblfyIyE/gSaC8iOSIyxuuaXNAXuAHfUcFK5+dyr4tyQXPgMxFZje8/7f+qarWndIQ6uyLDGBNW7EjPGBNWLPSMMWHFQs8YE1Ys9IwxYcVCzxgTViz0TMATkaJSU09W+rMDjogkh3LHGfNjUV4XYEwFHHMutTKm2uxIzwQtEckWkf8RkTVOX7m2zvJkEflURFaLyCci0tpZ3lRE3nT6z60SkT7OpiJF5EWnJ91HztUNJkRZ6JlgULvMx9vrSr2Wr6rpwD/wdeMA+D9guqp2Bl4GJjjLJwBfOP3nLgBKrrhpBzyrqh2BA8BQV/fGeMquyDABT0QOq2q9cpZn42uiudVpMPCdqiaIyF6guaqedJZ/q6qNnZu+J6nqiVLbSMZ3+VY75/kDQLSq/rEGds14wI70TLDT0zyujBOlHhdh33WHNAs9E+yuK/Xrl87jhfg6cgCMAOY5jz8B7oBTzTfja6pIEzjsfzQTDGo73YFL/EdVS6atNHS6jJwAhjvL7gKmishvgFzgJmf53cBEp7NMEb4A/Nbt4k1gse/0TNByvtPLUNW9Xtdigod9vDXGhBU70jPGhBU70jPGhBULPWNMWLHQM8aEFQs9Y0xYsdAzxoQVCz1jTFj5/5TBqok6Z0kTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## YOUR CODE HERE ##\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Plot training loss and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot training loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your model\n",
    "Using the previously created `DataLoader` for the test set, compute the percentage of correct predictions using the highest probability prediction. \n",
    "\n",
    "If your accuracy is over 90%, great work, but see if you can push a bit further! \n",
    "If your accuracy is under 90%, you'll need to make improvements.\n",
    "Go back and check your model architecture, loss function, and optimizer to make sure they're appropriate for an image classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 97.66%\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE ##\n",
    "# Evaluation loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    for data, target in test_dataloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs = model(data)\n",
    "        \n",
    "        # Get the index of the max probability\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the test images: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving your model\n",
    "\n",
    "Once your model is done training, try tweaking your hyperparameters and training again below to improve your accuracy on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [250/469], Loss: 0.6454\n",
      "Epoch [1/10], Average Loss: 0.8247\n",
      "Epoch [2/10], Average Loss: 0.4522\n",
      "Epoch [3/10], Step [250/469], Loss: 0.3443\n",
      "Epoch [3/10], Average Loss: 0.3845\n",
      "Epoch [4/10], Step [250/469], Loss: 0.2613\n",
      "Epoch [4/10], Average Loss: 0.3497\n",
      "Epoch [5/10], Average Loss: 0.3236\n",
      "Epoch [6/10], Step [250/469], Loss: 0.2621\n",
      "Epoch [6/10], Average Loss: 0.3136\n",
      "Epoch [7/10], Step [250/469], Loss: 0.3713\n",
      "Epoch [7/10], Average Loss: 0.2953\n",
      "Epoch [8/10], Average Loss: 0.2824\n",
      "Epoch [9/10], Step [250/469], Loss: 0.2962\n",
      "Epoch [9/10], Average Loss: 0.2744\n",
      "Epoch [10/10], Step [250/469], Loss: 0.3247\n",
      "Accuracy of the model on the test images: 95.57%\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE ##\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Improved Neural Network Architecture with Dropout and Batch Normalization\n",
    "class ImprovedNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImprovedNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the improved model\n",
    "model = ImprovedNN().to(device)\n",
    "\n",
    "# Specify the loss function and optimizer with a modified learning rate\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Load datasets with new transformations\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Define DataLoaders with new batch size\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if (batch_idx + 1) % 250 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_dataloader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    avg_loss = running_loss / len(train_dataloader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Evaluation loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the test images: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving your model\n",
    "Using `torch.save`, save your model for future loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to Ny_MNIST_Handwritten_Digits-STARTER_nn_model.pth\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE ##\n",
    "\n",
    "# Define the file path where you want to save your model\n",
    "model_path = 'Ny_MNIST_Handwritten_Digits-STARTER_nn_model.pth'\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
